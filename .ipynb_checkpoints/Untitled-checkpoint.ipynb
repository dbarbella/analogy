{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify the type of classifer you want to use: svm/naive/max_ent? svm\n",
      "LinearSvc:  0.633333333333\n",
      "Precision Score 0.450819672131\n",
      "Recall Score 0.40293040293\n",
      "F1 Score 0.425531914894\n",
      "\n",
      "Svc:  0.662962962963\n",
      "Precision Score 0.0\n",
      "Recall Score 0.0\n",
      "F1 Score 0.0\n",
      "\n",
      "NuSvc:  <SklearnClassifier(0.39753086419753086)>\n",
      "Precision Score 0.35836627141\n",
      "Recall Score 0.996336996337\n",
      "F1 Score 0.527131782946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/mnt/lovelace/software/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from analogy_strings import analogy_string_list\n",
    "from sentence_parser import get_speech_tags\n",
    "from personal import root\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#------------------------\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from nltk.classify import maxent\n",
    "import sys\n",
    "#------------------------\n",
    "import random\n",
    "import re\n",
    "from boyer_moore import find_boyer_moore\n",
    "\n",
    "# Implementation of the classifier to detect analogy.\n",
    "# From http://www.nltk.org/book/ch06.html\n",
    "\n",
    "analogy_file_name = \"test_extractions/bc_analogy.txt\"\n",
    "non_analogy_file_name = \"test_extractions/bc_ground.txt\"\n",
    "\n",
    "def get_analogy_string(text, mode):\n",
    "    # Returns a tuple of the first analogy indicator along with its speech tag in the text.\n",
    "    # e.g. (('as', 'RB'), ('fast', 'RB'), ('as', 'IN'))\n",
    "    result = []\n",
    "    tokens = text.split()\n",
    "    tagged_text = nltk.pos_tag(tokens)\n",
    "\n",
    "    for pattern in analogy_string_list:\n",
    "        match_index = find_boyer_moore(tokens, pattern)\n",
    "        if match_index != -1:\n",
    "            for i in range(len(pattern)):\n",
    "                result.append(tagged_text[match_index + i])\n",
    "            if (mode == \"naive\" or mode == \"max_ent\"):\n",
    "                return {\"analogy_indicator:\" : tuple(result)}\n",
    "            elif (mode == \"svm\"):\n",
    "                return (result)\n",
    "\n",
    "    if (mode == \"naive\" or mode == \"max_ent\"):\n",
    "        return {\"analogy_indicator:\" : tuple(result)}\n",
    "    elif (mode == \"svm\"):\n",
    "        return (result)\n",
    "\n",
    "\n",
    "def get_list(filename):\n",
    "    # Returns all training data as a list\n",
    "    # File should be formatted as a text line followed '>' in the next line\n",
    "    # before a new text line.\n",
    "    list = []\n",
    "    file = open(filename, \"r\", encoding = \"utf-8\")\n",
    "    for line in file.readlines():\n",
    "        if line[0] != '>' and line != \"\\n\":\n",
    "            list.append(line)\n",
    "\n",
    "    return list\n",
    "\n",
    "\n",
    "analogy_list = get_list(analogy_file_name)\n",
    "non_analogy_list = get_list(non_analogy_file_name)\n",
    "\n",
    "# labeled data.\n",
    "samples = [(text, 'YES') for text in analogy_list] + [(text, 'NO') for text in non_analogy_list]\n",
    "random.shuffle(samples)\n",
    "\n",
    "# verify that the classifier is implemented\n",
    "mode = input(\"Please specify the type of classifer you want to use: svm/naive/max_ent? \")\n",
    "if (mode != \"svm\") and (mode != \"naive\") and (mode != \"max_ent\"):\n",
    "    sys.exit(\"This classifier has not been implemented yet.\")\n",
    "\n",
    "# divide data into training set and test set\n",
    "feature_sets = [(get_analogy_string(text, mode), label) for (text, label) in samples]\n",
    "train_set =  feature_sets[: 100]\n",
    "test_set = feature_sets[100 :]\n",
    "\n",
    "def print_result(test_labels, Svc_pred):\n",
    "    print(\"Precision Score \"+ str(precision_score(test_labels, Svc_pred, pos_label=\"YES\")))\n",
    "    print(\"Recall Score \"+ str(recall_score(test_labels, Svc_pred, pos_label=\"YES\")))\n",
    "    print(\"F1 Score \"+ str(f1_score(test_labels, Svc_pred, pos_label=\"YES\"))+\"\\n\")\n",
    "    \n",
    "# change behavior according to the classifier\n",
    "if mode == \"naive\":\n",
    "    # train classifier with training set\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    # test classifier\n",
    "    print(nltk.classify.accuracy(classifier, test_set))\n",
    "    print(classifier.show_most_informative_features(1))\n",
    "\n",
    "elif mode == \"svm\":\n",
    "    # Preparing the data\n",
    "    train_data = [text for (text, label) in train_set]\n",
    "    train_labels = [label for (text, label) in train_set]\n",
    "    test_data = [text for (text, label) in test_set]\n",
    "    test_labels = [label for (text, label) in test_set]\n",
    "    \n",
    "    TfidfVect = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "    TfidfTrans = TfidfVect.fit_transform(train_data)\n",
    "    TfidfTrans_test = TfidfVect.transform(test_data)\n",
    "    \n",
    "    # LinearSVC\n",
    "    LinearSvc = LinearSVC().fit(TfidfTrans, train_labels).score(TfidfTrans_test, test_labels)\n",
    "    LinerarSvc_pred = LinearSVC().fit(TfidfTrans, train_labels).predict(TfidfTrans_test)\n",
    "    \n",
    "    # SVC\n",
    "    Svc = SVC().fit(TfidfTrans, train_labels).score(TfidfTrans_test, test_labels)\n",
    "    Svc_pred = SVC().fit(TfidfTrans, train_labels).predict(TfidfTrans_test)\n",
    "    # NuSVC\n",
    "    NuSvc = SklearnClassifier(NuSVC().fit(TfidfTrans, train_labels).score(TfidfTrans_test, test_labels))\n",
    "    NuSvc_pred = NuSVC().fit(TfidfTrans, train_labels).predict(TfidfTrans_test)\n",
    "    \n",
    "    print(\"LinearSvc: \", LinearSvc)\n",
    "    print_result(test_labels, LinerarSvc_pred)\n",
    "\n",
    "    print(\"Svc: \", Svc)\n",
    "    print_result(test_labels, Svc_pred)\n",
    "\n",
    "    print(\"NuSvc: \", NuSvc)\n",
    "    print_result(test_labels, NuSvc_pred)\n",
    "    \n",
    "   \n",
    "elif mode == \"max_ent\":\n",
    "    max_ent = nltk.classify.MaxentClassifier.train(train_set, 'GIS', trace=0, max_iter=1000)\n",
    "    print(\"Maximum Entropy: \")\n",
    "    print(nltk.classify.accuracy(max_ent, test_set))\n",
    "    print(max_ent.show_most_informative_features(5))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
